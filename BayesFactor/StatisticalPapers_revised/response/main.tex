\documentclass[11pt]{article}
 
\newcommand\CG[1]{\textcolor{red}{#1}}

\usepackage{lineno,hyperref}

\usepackage[margin=1 in]{geometry}
\renewcommand{\baselinestretch}{1.25}


%\usepackage{refcheck}
\usepackage{authblk}
\usepackage{galois} % composition function \comp
\usepackage{bm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{amsthm}
\usepackage[authoryear]{natbib}
\usepackage{graphicx}
\usepackage{color}
\usepackage{booktabs}
\usepackage[page,title]{appendix}
%\renewcommand\appendixname{haha}
\usepackage{enumerate}
\usepackage{changepage}
\usepackage{datetime}
\usepackage[FIGTOPCAP]{subfigure}
\newdate{date}{9}{1}{2017}

%%%%%%%%%%%%%%  Notations %%%%%%%%%%
\DeclareMathOperator{\mytr}{tr}
\DeclareMathOperator{\mydiag}{diag}
\DeclareMathOperator{\myRank}{Rank}
\DeclareMathOperator{\myP}{P}
\DeclareMathOperator{\myE}{E}
\DeclareMathOperator{\myVar}{Var}
\DeclareMathOperator{\myCov}{Cov}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}


\newcommand{\Ba}{\mathbf{a}}    \newcommand{\Bb}{\mathbf{b}}    \newcommand{\Bc}{\mathbf{c}}    \newcommand{\Bd}{\mathbf{d}}    \newcommand{\Be}{\mathbf{e}}    \newcommand{\Bf}{\mathbf{f}}    \newcommand{\Bg}{\mathbf{g}}    \newcommand{\Bh}{\mathbf{h}}    \newcommand{\Bi}{\mathbf{i}}    \newcommand{\Bj}{\mathbf{j}}    \newcommand{\Bk}{\mathbf{k}}    \newcommand{\Bl}{\mathbf{l}}
\newcommand{\Bm}{\mathbf{m}}    \newcommand{\Bn}{\mathbf{n}}    \newcommand{\Bo}{\mathbf{o}}    \newcommand{\Bp}{\mathbf{p}}    \newcommand{\Bq}{\mathbf{q}}    \newcommand{\Br}{\mathbf{r}}    \newcommand{\Bs}{\mathbf{s}}    \newcommand{\Bt}{\mathbf{t}}    \newcommand{\Bu}{\mathbf{u}}    \newcommand{\Bv}{\mathbf{v}}    \newcommand{\Bw}{\mathbf{w}}    \newcommand{\Bx}{\mathbf{x}}
\newcommand{\By}{\mathbf{y}}    \newcommand{\Bz}{\mathbf{z}}    
\newcommand{\BA}{\mathbf{A}}    \newcommand{\BB}{\mathbf{B}}    \newcommand{\BC}{\mathbf{C}}    \newcommand{\BD}{\mathbf{D}}    \newcommand{\BE}{\mathbf{E}}    \newcommand{\BF}{\mathbf{F}}    \newcommand{\BG}{\mathbf{G}}    \newcommand{\BH}{\mathbf{H}}    \newcommand{\BI}{\mathbf{I}}    \newcommand{\BJ}{\mathbf{J}}    \newcommand{\BK}{\mathbf{K}}    \newcommand{\BL}{\mathbf{L}}
\newcommand{\BM}{\mathbf{M}}    \newcommand{\BN}{\mathbf{N}}    \newcommand{\BO}{\mathbf{O}}    \newcommand{\BP}{\mathbf{P}}    \newcommand{\BQ}{\mathbf{Q}}    \newcommand{\BR}{\mathbf{R}}    \newcommand{\BS}{\mathbf{S}}    \newcommand{\BT}{\mathbf{T}}    \newcommand{\BU}{\mathbf{U}}    \newcommand{\BV}{\mathbf{V}}    \newcommand{\BW}{\mathbf{W}}    \newcommand{\BX}{\mathbf{X}}
\newcommand{\BY}{\mathbf{Y}}    \newcommand{\BZ}{\mathbf{Z}}    

\newcommand{\bfsym}[1]{\ensuremath{\boldsymbol{#1}}}

 \def\balpha{\bfsym \alpha}
 \def\bbeta{\bfsym \beta}
 \def\bgamma{\bfsym \gamma}             \def\bGamma{\bfsym \Gamma}
 \def\bdelta{\bfsym {\delta}}           \def\bDelta {\bfsym {\Delta}}
 \def\bfeta{\bfsym {\eta}}              \def\bfEta {\bfsym {\Eta}}
 \def\bmu{\bfsym {\mu}}                 \def\bMu {\bfsym {\Mu}}
 \def\bnu{\bfsym {\nu}}
 \def\btheta{\bfsym {\theta}}           \def\bTheta {\bfsym {\Theta}}
 \def\beps{\bfsym \varepsilon}          \def\bepsilon{\bfsym \epsilon}
 \def\bsigma{\bfsym \sigma}             \def\bSigma{\bfsym \Sigma}
 \def\blambda {\bfsym {\lambda}}        \def\bLambda {\bfsym {\Lambda}}
 \def\bomega {\bfsym {\omega}}          \def\bOmega {\bfsym {\Omega}}
 \def\brho   {\bfsym {\rho}}
 \def\btau{\bfsym {\tau}}
 \def\bxi{\bfsym {\xi}}
 \def\bzeta{\bfsym {\zeta}}
% May add more in future.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\theoremstyle{plain}
\newtheorem{theorem}{\quad\quad Theorem}
\newtheorem{proposition}{\quad\quad Proposition}
\newtheorem{corollary}{\quad\quad Corollary}
\newtheorem{lemma}{\quad\quad Lemma}
\newtheorem{example}{Example}
\newtheorem{assumption}{\quad\quad Assumption}
\newtheorem{condition}{\quad\quad Condition}

\theoremstyle{definition}
\newtheorem{definition}{\quad\quad Definition}
\newtheorem{remark}{\quad\quad Remark}
\theoremstyle{remark}





\begin{document}
\title{
Response to Reviewers
``
Nonexistence of unbiased test for high-dimensional linear model and a Bayesian-motivated test 
''
}



\author[1]{Rui Wang}
\author[1,2]{Xingzhong Xu\thanks{Corresponding author\\Email address: xuxz@bit.edu.cn}}
\affil[1]{
School of Mathematics and Statistics, Beijing Institute of Technology, Beijing 
    100081,China
}
\affil[2]{
Beijing Key Laboratory on MCAACI, Beijing Institute of Technology, Beijing 100081,China
}

\maketitle

We thank both reviewer for their helpful comments and critiques.
We have carefully considered the comments and made corresponding changes to the paper.
Our responds are as follows.

\section{Response to reviewer 1}

\textbf{
    1.
    The manuscript should provide comparison with the literature that exploits sparsity because under the null hypothesis the model parameter is sparse (with at most $q$ non-zero entries).
    For example, \cite{zhang2016simultaneous} studies the same problem of testing (high-dimensional components) of linear regressions. Apart from assuming random designs, this literature attempts to detect deviations in $l_\infty$-norm, while the current manuscript seems to aim at detecting deviations in
    $l_2$-norm.
    In my opinion, more discussion on this literature would be helpful so that the reader would get a fair impression on what has been done and what assumptions different methods require.
    For example, here symmetry of error distribution is needed (Assumption 1), which is not usually required in the literature on high-dimensional inference.
}

\textbf{Answer:}


\textbf{
    2.
    Theorem 4 provides the power analysis, but its assumption in Equation (8) needs more discussion.
    For example, at the end of Section 3, the manuscript uses the factor model to illustrate the power of the proposed test over Goeman et al. (2006).
    However, this discussion is based on Theorem 4 and my rough calculation suggests that Equation (8), which is required by Theorem 4, does not seem to hold for factor models.
    Let me outline some details.
    \begin{enumerate}[(a)]
        \item 
            Supppose that $q=0$ (so $\tilde \BU_a = \BI_n$) and $\BX_b= \begin{pmatrix} W_1^\top \\ \vdots \\ W_n^\top \end{pmatrix}$ with $W_i = B F_i + u_i$, where $F_i$ is a scalar from i.i.d. $\mathcal N(0,1)$, $u_i$ is from $\mathcal N(0, \BI_p)$ and $B$ is from $\mathcal N (0, \BI_p)$.
            Assume $F_i$, $u_i$ and $B$ are independent.
        \item
            Since $\myE (\gamma_I^{2k}) \geq \myVar (\gamma_I^k)$, a necessary condition for Equation (8) is
            \begin{equation*}
                \frac{(\gamma_1^k - \myE_I(\gamma_I^k))^2}{n\myE_I (\gamma_I^{2k})} \to 0,
            \end{equation*}
            where $\myE_I$ denotes expectation taken over randomness of $I$.
        \item
            Based on the computation above Theorem 4 (i.e. $\myE_I (\gamma_I^k) = \mytr (\BX_b \BX_b^\top)^k /n$), we know that $\myE_I (\gamma_I) = n^{-1} \sum_{i=1}^n W_i^\top W_i$ and 
            \begin{equation*}
                \myE_I (\gamma_I^2)  = n^{-1} \sum_{i=1}^n (W_i^\top W_i)^2 + n^{-1}\sum_{i=1}^n \sum_{j=1, j\neq i}^n (W_i^\top W_j)^2.
            \end{equation*}
        \item
            For $k=1$, we use the assumptions in (a) to determined the size of $\gamma_1$, $\myE_I (\gamma_I)$ and $\myE_I (\gamma_I^2)$.
            Simple computations would give use $\myE W_i^\top W_i = 2p$, $\myE (W_i^\top W_i)^2 = 6p^2 + 10p$ and $\myE (W_i^\top W_j)^2 = p^2 + 5p$ for $i\neq j$.
            Thus, $\gamma_1 = O_p(np)$, $\myE_I (\gamma_I) = O_p(p)$ and $\myE_I (\gamma_I^2) = O_p(np^2)$. Thus, $\frac{(\gamma_I^k - \myE_i (\gamma_I^k))^2}{n\myE_I (\gamma_I^{2k})}$ with $k=1$ seem to be of the order $O_P(1)$ instead of $o_P(1)$.
        \item
            Overall, I think discussions on why Equation (8) should hold is needed, at least for the examples used at the end of Section 4 (i.i.d. rows and factor models).
    \end{enumerate}
}

\textbf{Answer:}

\textbf{
    3.
    I think the power comparison with \cite{Goeman2006} should be more
    formal. Currently, there is a comparison on when $\myCov(-\gamma_I^{-1}, \gamma_I w_I^2)$ and $\myCov(\gamma_I, \gamma_I \omega_I^2)$ are positive.
    However, in the two expressions for asymptotic power on page 12, this is not the only difference.
    For example, there is also $\myVar (\gamma_I)$ versus $\myVar(\gamma_I^{-1})$.
    Therefore, in the end, which one is more powerful is not completely obvious to me.
    Even in the simple case of $w_i = 0$ for $i = 1, ..., nâˆ’q$, I am not certain which test has better asymptotic power.
I think a formal result comparing the power of the two test would be nice
even under restricted assumptions.
}


\section{Response to reviewer 2}





\section{List of major changes}






\bibliographystyle{apalike}
\bibliography{mybibfile}



\end{document}
